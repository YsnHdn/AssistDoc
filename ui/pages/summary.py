"""
Page de r√©sum√© de l'application AssistDoc.
Permet de g√©n√©rer des r√©sum√©s des documents avec diff√©rentes options.
Mise √† jour pour supporter l'isolation des donn√©es par utilisateur.
"""

import streamlit as st
import time
import os
from pathlib import Path
import io

# Import des modules de l'application
from ui.components.visualization import display_summary, display_model_info
from src.vector_db.retriever import create_user_aware_retriever
from src.llm.models import LLMConfig, LLMProvider, create_llm
from utils.session_utils import get_user_id, get_user_data_path

def detect_streamlit_cloud():
    """D√©tecte si l'application s'ex√©cute sur Streamlit Cloud"""
    return os.path.exists("/mount/src")

def show_summary_page():
    """
    Affiche la page de g√©n√©ration de r√©sum√© avec isolation par utilisateur.
    """
    # Titre de la page
    st.markdown("<h1 class='main-title'>R√©sum√© de Documents üìù</h1>", unsafe_allow_html=True)
    
    # Obtenir l'ID utilisateur
    user_id = get_user_id()
    
    # V√©rifier si des documents sont charg√©s pour cet utilisateur
    if not st.session_state.get("documents", []) or not st.session_state.get("vector_store_initialized", False):
        st.warning("Aucun document charg√©. Veuillez d'abord charger et indexer des documents dans la barre lat√©rale.")
        return
    
    # Informations sur le mod√®le utilis√©
    display_model_info()
    
    # Panneau de configuration du r√©sum√©
    with st.expander("Options de r√©sum√©", expanded=True):
        # S√©lection du document √† r√©sumer
        doc_options = [doc.get("file_name", f"Document {i+1}") for i, doc in enumerate(st.session_state.documents)]
        
        selected_doc = st.selectbox(
            "Document √† r√©sumer",
            options=doc_options
        )
        
        # Obtenir l'index du document s√©lectionn√©
        selected_doc_index = doc_options.index(selected_doc)
        selected_doc_id = st.session_state.documents[selected_doc_index].get("file_name")
        
        # Longueur du r√©sum√©
        col1, col2 = st.columns(2)
        
        with col1:
            length_options = {
                "court": "Court (environ 150 mots)",
                "moyen": "Moyen (environ 300 mots)",
                "long": "Long (environ 500 mots)",
                "personnalis√©": "Personnalis√©"
            }
            
            summary_length = st.selectbox(
                "Longueur du r√©sum√©",
                options=list(length_options.keys()),
                format_func=lambda x: length_options[x],
                index=1  # Option par d√©faut: moyen
            )
            
            # Si longueur personnalis√©e
            if summary_length == "personnalis√©":
                custom_length = st.number_input("Nombre de mots", min_value=50, max_value=1000, value=300, step=50)
                summary_length_value = f"environ {custom_length} mots"
            else:
                # Convertir l'option en valeur utilisable
                summary_length_map = {
                    "court": "environ 150 mots",
                    "moyen": "environ 300 mots",
                    "long": "environ 500 mots"
                }
                summary_length_value = summary_length_map.get(summary_length, "environ 300 mots")
        
        with col2:
            # Style du r√©sum√©
            style_options = {
                "informatif": "Informatif (factuel)",
                "analytique": "Analytique (critique)",
                "simplifi√©": "Simplifi√© (vulgaris√©)",
                "bullet_points": "Points cl√©s (liste)"
            }
            
            summary_style = st.selectbox(
                "Style du r√©sum√©",
                options=list(style_options.keys()),
                format_func=lambda x: style_options[x],
                index=0  # Option par d√©faut: informatif
            )
        
        # S√©lection des documents √† r√©sumer (si plusieurs sont charg√©s)
        if len(st.session_state.documents) > 1:
            multi_doc = st.checkbox("Inclure d'autres documents dans le r√©sum√©", value=False)
            
            if multi_doc:
                additional_docs = st.multiselect(
                    "Documents additionnels",
                    options=[doc for doc in doc_options if doc != selected_doc],
                    default=[],
                    help="S√©lectionnez des documents suppl√©mentaires √† inclure dans le r√©sum√©"
                )
                
                # Ajouter le document principal aux documents s√©lectionn√©s
                selected_docs = [selected_doc] + additional_docs
                
                # Filtrer les documents s√©lectionn√©s
                selected_doc_indices = [i for i, name in enumerate(doc_options) if name in selected_docs]
            else:
                # Si un seul document est s√©lectionn√©
                selected_doc_indices = [selected_doc_index]
        else:
            # Si un seul document est charg√©, le s√©lectionner automatiquement
            selected_doc_indices = [0]
    
    # Bouton pour g√©n√©rer le r√©sum√©
    if st.button("G√©n√©rer le r√©sum√©", type="primary", use_container_width=True):
        # V√©rifier qu'au moins un document est s√©lectionn√©
        if not selected_doc_indices:
            st.error("Veuillez s√©lectionner au moins un document √† r√©sumer")
            return
        
        # G√©n√©rer le r√©sum√©
        with st.spinner("G√©n√©ration du r√©sum√© en cours..."):
            summary_text, metadata = generate_summary(
                summary_length_value,
                summary_style,
                selected_doc_indices,
                user_id
            )
        
        # Afficher le r√©sum√©
        if summary_text:
            display_summary(summary_text, metadata)
            
            # Permettre le t√©l√©chargement du r√©sum√©
            offer_download(summary_text, metadata)

def generate_summary(length, style, doc_indices, user_id):
    """
    G√©n√®re un r√©sum√© des documents s√©lectionn√©s pour un utilisateur sp√©cifique.
    
    Args:
        length: Longueur souhait√©e pour le r√©sum√©
        style: Style souhait√© pour le r√©sum√©
        doc_indices: Indices des documents √† r√©sumer
        user_id: Identifiant unique de l'utilisateur
        
    Returns:
        Tuple contenant (texte du r√©sum√©, m√©tadonn√©es)
    """
    try:
        # R√©cup√©rer les param√®tres de configuration LLM
        provider = st.session_state.llm_provider
        model = st.session_state.llm_model
        
        # R√©cup√©rer les informations d'authentification
        from utils.api_helpers import get_api_credentials
        api_key, api_base = get_api_credentials(provider)

        # V√©rifier si GitHub Inference est choisi sans cl√© API
        if provider == "github_inference" and not api_key:
            return "Erreur: API GitHub Inference non configur√©e. Contactez l'administrateur ou choisissez un mod√®le Hugging Face.", []

        # Cr√©er la configuration LLM
        config = LLMConfig(
            provider=provider,
            model_name=model,
            api_key=api_key,
            api_base=api_base,
            temperature=0.7,
            max_tokens=1500  # Augmenter pour les r√©sum√©s
        )
        
        # Si c'est Hugging Face, ajouter des param√®tres sp√©cifiques
        if provider == "huggingface":
            config.extra_params["use_api"] = True
        
        # Cr√©er le LLM
        llm = create_llm(config)
        
        # Cr√©er le retriever sp√©cifique √† l'utilisateur
        user_vector_store_path = str(get_user_data_path(user_id) / "vector_store")
        store_type = "faiss"  # Utiliser FAISS pour assurer la compatibilit√©
        retriever = create_user_aware_retriever(
            user_id=user_id,
            store_path=user_vector_store_path,
            embedder_model="all-MiniLM-L6-v2",
            store_type=store_type,
            top_k=10
        )
        
        # Obtenir les noms des documents s√©lectionn√©s
        selected_doc_names = [st.session_state.documents[i].get("file_name") for i in doc_indices]
        
        # Cartographier les styles aux textes descriptifs
        style_map = {
            "informatif": "informatif et factuel",
            "analytique": "analytique avec des insights",
            "simplifi√©": "simplifi√© et accessible",
            "bullet_points": "sous forme de liste √† puces des points cl√©s"
        }
        style_description = style_map.get(style, "informatif et factuel")
        
        # R√©cup√©rer les chunks pertinents sp√©cifiques √† l'utilisateur
        all_chunks = []
        for doc_name in selected_doc_names:
            doc_chunks = retriever.retrieve(
                query=f"Contenu important de {doc_name}", 
                top_k=20,
                filter_metadata={"file_name": doc_name}  # Filtre explicite pour ce document
            )
            
            all_chunks.extend(doc_chunks)
        
        # Extraire le texte de tous les chunks
        document_text = ""
        for i, chunk in enumerate(all_chunks):
            document_text += f"--- Extrait {i+1} ---\n"
            document_text += chunk.get("text", "") + "\n\n"
        
        # Syst√®me prompt tr√®s explicite
        system_prompt = f"""Tu es un assistant sp√©cialis√© dans la cr√©ation de r√©sum√©s.
        Tu vas recevoir des extraits d'un ou plusieurs documents, et tu dois en faire un r√©sum√©.
        Le r√©sum√© doit √™tre {style_description} et faire {length}.
        Ne demande pas plus d'informations et ne mentionne pas que tu r√©sumes des extraits.
        Produis directement un r√©sum√© coh√©rent et bien structur√©."""
        
        # Prompt utilisateur direct
        user_prompt = f"""Voici des extraits de document(s) √† r√©sumer:

{document_text}

Cr√©e un r√©sum√© {style_description} de {length}. Le r√©sum√© doit √™tre clair, coh√©rent et couvrir les points principaux des extraits fournis."""
        
        # G√©n√©rer directement la r√©ponse avec le LLM
        llm_response = llm.generate(user_prompt, system_prompt=system_prompt)
        
        # Cr√©er les m√©tadonn√©es pour l'affichage
        metadata = {
            "length": length.split()[-2] if "environ" in length else length,
            "style": style,
            "num_docs": len(doc_indices),
            "doc_names": ", ".join(selected_doc_names),
            "sources": all_chunks[:5]  # Limiter le nombre de sources pour l'affichage
        }
        
        return llm_response.content, metadata
        
    except Exception as e:
        import traceback
        error_text = f"Erreur lors de la g√©n√©ration du r√©sum√©: {str(e)}\n\n{traceback.format_exc()}"
        st.error(error_text)
        return f"Erreur: {str(e)}", {}

def offer_download(summary_text, metadata):
    """
    Offre des options pour t√©l√©charger le r√©sum√©.
    
    Args:
        summary_text: Texte du r√©sum√©
        metadata: M√©tadonn√©es du r√©sum√©
    """
    # Pr√©parer le contenu du fichier
    buffer = io.StringIO()
    
    # Ajouter un en-t√™te
    buffer.write(f"# R√©sum√© g√©n√©r√© par AssistDoc\n\n")
    buffer.write(f"Style: {metadata.get('style', 'Standard')}\n")
    buffer.write(f"Longueur: {metadata.get('length', 'N/A')}\n")
    buffer.write(f"Documents: {metadata.get('num_docs', 'N/A')}\n\n")
    
    # Ajouter le r√©sum√©
    buffer.write("## R√©sum√©\n\n")
    buffer.write(summary_text)
    
    # Ajouter les sources si disponibles
    if "sources" in metadata and metadata["sources"]:
        buffer.write("\n\n## Sources\n\n")
        for i, source in enumerate(metadata["sources"], 1):
            doc_name = source.get("file_name", "Document inconnu")
            text_snippet = source.get("text", "")[:100] + "..."
            buffer.write(f"{i}. **{doc_name}**: {text_snippet}\n\n")
    
    # Ajouter un pied de page
    buffer.write("\n---\n")
    buffer.write("G√©n√©r√© avec AssistDoc - Assistant intelligent pour vos documents")
    
    # Proposer le t√©l√©chargement
    st.download_button(
        label="T√©l√©charger le r√©sum√©",
        data=buffer.getvalue(),
        file_name="resume_assistdoc.md",
        mime="text/markdown",
    )
